{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq LSTM model - Translate and Predict\n",
    "\n",
    "The encoder-decoder model provides a pattern for using recurrent neural networks to address challenging sequence-to-sequence prediction problems such as machine translation.\n",
    "\n",
    "Encoder-decoder models can be developed in the Keras Python deep learning library and an example of a neural machine translation system developed with this model has been described on the Keras blog, with sample code distributed with the Keras project.\n",
    "\n",
    "This example can provide the basis for developing encoder-decoder LSTM models for your own sequence-to-sequence prediction problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HL6SiZJT2oUb"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1GSnVx0M2oUe"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lxNfeYx2oUg"
   },
   "source": [
    "## 1. Prepare data\n",
    "Data for this exercise can be downloaded from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ih9pRZKjBb1e"
   },
   "source": [
    "### 1.1 Download and extract sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v53t6LIx4GP6"
   },
   "outputs": [],
   "source": [
    "!wget http://www.manythings.org/anki/hin-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kBfzcXuX4wUI"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rLcBzQc940OL"
   },
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('hin-eng.zip', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dCQ5Oqyq5aI7"
   },
   "outputs": [],
   "source": [
    "data = ''\n",
    "with zf.open('hin.txt') as readfile:\n",
    "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
    "    data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0pCOcxYN8tcD"
   },
   "outputs": [],
   "source": [
    "data =  data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vddBlWzORWYk"
   },
   "outputs": [],
   "source": [
    "data[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Qju7Jty2oUj"
   },
   "source": [
    "Review the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0F4swvCT2oUk"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpU9MUMx2oUp"
   },
   "source": [
    "### 1.2 Separate out Encoder and Decoder input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RN3q2mm42oUp"
   },
   "outputs": [],
   "source": [
    "encoder_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V6TdW_s22oUs"
   },
   "outputs": [],
   "source": [
    "decoder_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rfWDMX2q2oUu"
   },
   "outputs": [],
   "source": [
    "for line in data:\n",
    "    try:\n",
    "        in_txt, out_txt = line.split('\\t')\n",
    "        encoder_text.append(in_txt)\n",
    "        \n",
    "        # Add tab '<start>' as 'start sequence in target\n",
    "        # And '<end>' as End\n",
    "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
    "    except:\n",
    "        pass #ignore data which goes into error        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EEMPoLsH2oUw"
   },
   "outputs": [],
   "source": [
    "decoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f0A7ThBD2oUz"
   },
   "outputs": [],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_INkpPE2oU2"
   },
   "source": [
    "### 1.3 Build Sequences for Encoder and Decoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AzgIJwqZ2oU3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGUFyI452oU5"
   },
   "source": [
    "Encoder tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kzg86E_h2oU5"
   },
   "outputs": [],
   "source": [
    "encoder_t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eh0Ou8x92oU8"
   },
   "outputs": [],
   "source": [
    "encoder_t.fit_on_texts(encoder_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1VczEXUy2oU_"
   },
   "outputs": [],
   "source": [
    "encoder_seq = encoder_t.texts_to_sequences(encoder_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pgUJ7WSz2oVC"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ycdr_8ZF2oVE"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3yQrwZcz2oVI"
   },
   "outputs": [],
   "source": [
    "encoder_vocab_size = len(encoder_t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ysng0igB2oVK"
   },
   "outputs": [],
   "source": [
    "encoder_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cvRxfJKdSz5w"
   },
   "outputs": [],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AM4-L-IOSncW"
   },
   "outputs": [],
   "source": [
    "encoder_seq[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxRm7g5_2oVO"
   },
   "source": [
    "Decoder tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qX3ALB6d2oVP"
   },
   "outputs": [],
   "source": [
    "decoder_t = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d1AGCzWs2oVT"
   },
   "outputs": [],
   "source": [
    "decoder_t.fit_on_texts(decoder_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1zWovfgB2oVa"
   },
   "outputs": [],
   "source": [
    "decoder_seq = decoder_t.texts_to_sequences(decoder_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9xHVbCk_2oVc"
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l4tIpef02oVe"
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3IWtCcE42oVh"
   },
   "outputs": [],
   "source": [
    "decoder_vocab_size = len(decoder_t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nfxwsKKr2oVj"
   },
   "outputs": [],
   "source": [
    "decoder_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NaywgIDQTOkz"
   },
   "outputs": [],
   "source": [
    "decoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CRnT4mPaTSOH"
   },
   "outputs": [],
   "source": [
    "decoder_seq[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOkCZLP02oVp"
   },
   "source": [
    "### 1.4 Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7sK7hzn62oVq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6SSPgzlg2oVu"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = pad_sequences(encoder_seq, maxlen=max_encoder_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Du2xjQhm2oVy"
   },
   "outputs": [],
   "source": [
    "decoder_input_data = pad_sequences(decoder_seq, maxlen=max_decoder_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ukutQ_Ra2oV1"
   },
   "outputs": [],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DE3Lt9xT2oV6"
   },
   "outputs": [],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0hWqo3K2oV8"
   },
   "source": [
    "Integer to Word converter for Decoder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YroNA85k2oV9"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "myI-TKwV2oV_"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNqNaJ4t2oWB"
   },
   "source": [
    "### 1.5 Building Decoder Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E8Jojsni2oWC"
   },
   "outputs": [],
   "source": [
    "decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "X77FSz232oWD"
   },
   "outputs": [],
   "source": [
    "for i in range(decoder_input_data.shape[0]):\n",
    "    for j in range(1,decoder_input_data.shape[1]):\n",
    "        decoder_target_data[i][j-1] = decoder_input_data[i][j]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UR7_nAZB2oWF"
   },
   "outputs": [],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JtaVtmyQ2oWM"
   },
   "outputs": [],
   "source": [
    "decoder_target_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkfOv-Jg2oWP"
   },
   "source": [
    "Convert target data in one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YLfOe0k52oWQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import  to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7oSeXtY42oWS"
   },
   "outputs": [],
   "source": [
    "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], \n",
    "                                   decoder_input_data.shape[1],\n",
    "                                   len(decoder_t.word_index)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TlPCKFaM2oWU"
   },
   "outputs": [],
   "source": [
    "for i in range(decoder_target_data.shape[0]):\n",
    "    for j in range(decoder_target_data.shape[1]):\n",
    "        decoder_target_one_hot[i][j] = to_categorical(decoder_target_data[i][j],\n",
    "                                                      num_classes=len(\n",
    "                                                          decoder_t.word_index)+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5TxHo1KnVffx"
   },
   "outputs": [],
   "source": [
    "decoder_target_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEaq66iJ2oWX"
   },
   "source": [
    "## 2. Building the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OevwCnTV2oWY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEKx9XQI2oWb"
   },
   "source": [
    "Define config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SfHikNyh2oWc"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_size = 50\n",
    "decoder_embedding_size = 50\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktTTJ3t_2oWg"
   },
   "source": [
    "### 2.1 Build Encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rx5XaerO2oWm"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DOMlr6uZ2oWq"
   },
   "outputs": [],
   "source": [
    "encoder_embedding = Embedding(encoder_vocab_size+1, encoder_embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sC-kyvJs2oWs"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_output = encoder_embedding(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c5uMqV0B2oWu"
   },
   "outputs": [],
   "source": [
    "x, state_h, state_c = LSTM(rnn_units,return_state=True)(encoder_embedding_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm1DgTrA2oWw"
   },
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxxLV14h2oWy"
   },
   "source": [
    "### 2.2 Build Decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OSqja3Z72oWy"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hWV4_0-w2oW0"
   },
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(decoder_vocab_size + 1, decoder_embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_Q2bG1so2oW1"
   },
   "outputs": [],
   "source": [
    "decoder_embedding_output = decoder_embedding(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p9WeX-AH2oW3"
   },
   "outputs": [],
   "source": [
    "decoder_rnn = LSTM(rnn_units, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HDnMtuGS2oW4"
   },
   "outputs": [],
   "source": [
    "#Initialize initial state with encoder_states\n",
    "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
    "x,_,_ = decoder_rnn(decoder_embedding_output, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tyKPLlNt2oW6"
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(decoder_vocab_size + 1, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6nFd03t02oW8"
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4irUZFFJ2oW-"
   },
   "source": [
    "### 2.3 Build Model using both Encoder and Decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "35Wan_LF2oW-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8onZYQE-2oXC"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "owbIRm0r2oXJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlutxik62oXL"
   },
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rqqgnzvC2oXM"
   },
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n",
    "          batch_size=64,\n",
    "          epochs=1000,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q0E7j5Cf2gaS"
   },
   "outputs": [],
   "source": [
    "model.save('drive/AI-ML/models/seq2seq_eng_hin_training.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diNsT2872oXO"
   },
   "source": [
    "## 4. Building Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1s0wEEW2oXP"
   },
   "source": [
    "### 4.1 Build the Encoder Model to predict Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zG_a4adu2oXQ"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-9JR6I72oXR"
   },
   "source": [
    "### 4.2 Build the Decoder Model \n",
    "\n",
    "1. Define Input for both 'h' state and 'c' state initialization\n",
    "2. Get RNN outputs along with h and c state\n",
    "3. Define Decoder Output\n",
    "4. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OwW75R1m2oXR"
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(rnn_units,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7C6We4N22oXT"
   },
   "outputs": [],
   "source": [
    "decoder_state_input_c = Input(shape=(rnn_units,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BtckkZac2oXV"
   },
   "outputs": [],
   "source": [
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4s74Mwv2oXW"
   },
   "source": [
    "Get RNN outputs, state(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "j9jk7INx2oXW"
   },
   "outputs": [],
   "source": [
    "x = decoder_embedding(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dlmAnhKP2oXX"
   },
   "outputs": [],
   "source": [
    "#We will use the layer which we trained earlier\n",
    "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BIo2MJ162oXb"
   },
   "outputs": [],
   "source": [
    "#Why do we need this?\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlSOV9tU2oXd"
   },
   "source": [
    "get Decoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "piCi4D3I2oXe"
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(rnn_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvP7HOzL2oXf"
   },
   "source": [
    "Build Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_Kbc3jAe2oXg"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,  #Model inputs\n",
    "                     [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJyeIiyN2oXj"
   },
   "source": [
    "## 5.0 Predicting Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQKbrF9b2oXj"
   },
   "source": [
    "Build a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ulVF4IHE2oXk"
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_sequence):\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    decoder_initial_states_value = encoder_model.predict(input_sequence)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted output with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter integer\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value for decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIcTe2V32oXl"
   },
   "source": [
    "Call Prediction function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vYC_2syR2oXm"
   },
   "outputs": [],
   "source": [
    "#Get a random sentence\n",
    "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
    "print(start_num)\n",
    "\n",
    "for i in range(start_num, start_num + 10):\n",
    "    input_seq = encoder_input_data[i : i+1]\n",
    "    predicted_sentence = decode_sentence(input_seq)\n",
    "    print('--------')\n",
    "    print ('Input sentence: ', encoder_text[i])\n",
    "    print ('Predicted sentence: ', predicted_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgZeXBIwy-NB"
   },
   "source": [
    "## 6. Save Prediction models and tokenizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4cPhW3Sfy8h6"
   },
   "outputs": [],
   "source": [
    "#Save encoder and decoder model for Prediction\n",
    "encoder_model.compile(optimizer='adam', loss='mse')\n",
    "decoder_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "encoder_model.save('drive/AI-ML/models/seq2seq_encoder_eng_hin.hd5')\n",
    "decoder_model.save('drive/AI-ML/models/seq2seq_decoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "05_mrMj2zTH9"
   },
   "outputs": [],
   "source": [
    "#Save tokenizers\n",
    "import pickle\n",
    "\n",
    "pickle.dump(encoder_t,open('drive/AI-ML/models/encoder_tokenizer_eng','wb'))\n",
    "pickle.dump(decoder_t,open('drive/AI-ML/models/decoder_tokenizer_hin','wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Seq2Seq LSTM Model - Translation.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
